{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835b22e2-8b39-471e-8f55-b8c5b9d29ac9",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Worldwide Earthquake Events API - Gold Layer Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59606d-8190-4a55-8733-b5e52f39d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, udf  # For conditional logic, column operations, and user-defined functions in Spark\n",
    "from pyspark.sql.types import StringType         # For specifying return type of UDFs\n",
    "# Ensure the below library is installed on your Fabric environment for reverse geocoding\n",
    "import reverse_geocoder as rg\n",
    "\n",
    "# ---------------------------\n",
    "# Gold Layer: Enrichment and Business Logic for Earthquake Data\n",
    "# ---------------------------\n",
    "\n",
    "# Read cleansed data from the silver layer, filtering for recent events (after start_date).\n",
    "# - The 'earthquake_events_silver' table is the output from the silver layer.\n",
    "df = spark.read.table(\"earthquake_events_silver\").filter(col('time') > start_date)\n",
    "\n",
    "# Define a function to retrieve the country code for a given latitude and longitude.\n",
    "# - Uses the reverse_geocoder library to map coordinates to country codes.\n",
    "def get_country_code(lat, lon):\n",
    "    \"\"\"\n",
    "    Retrieve the country code for a given latitude and longitude.\n",
    "\n",
    "    Parameters:\n",
    "    lat (float or str): Latitude of the location.\n",
    "    lon (float or str): Longitude of the location.\n",
    "\n",
    "    Returns:\n",
    "    str: Country code of the location, retrieved using the reverse geocoding API.\n",
    "\n",
    "    Example:\n",
    "    >>> get_country_code(48.8588443, 2.2943506)\n",
    "    'FR'\n",
    "    \"\"\"\n",
    "    coordinates = (float(lat), float(lon))\n",
    "    return rg.search(coordinates)[0].get('cc')\n",
    "\n",
    "# Register the UDF so it can be used on Spark DataFrames.\n",
    "get_country_code_udf = udf(get_country_code, StringType())\n",
    "\n",
    "# Add a 'country_code' column to the DataFrame using the UDF.\n",
    "df_with_location = (\n",
    "    df\n",
    "    .withColumn(\"country_code\", get_country_code_udf(col(\"latitude\"), col(\"longitude\")))\n",
    ")\n",
    "\n",
    "# Add a significance classification column ('sig_class') based on the 'sig' value.\n",
    "# - Classifies events as 'Low', 'Moderate', or 'High' significance.\n",
    "df_with_location_sig_class = (\n",
    "    df_with_location\n",
    "    .withColumn(\n",
    "        'sig_class',\n",
    "        when(col(\"sig\") < 100, \"Low\")\n",
    "        .when((col(\"sig\") >= 100) & (col(\"sig\") < 500), \"Moderate\")\n",
    "        .otherwise(\"High\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write the enriched and classified data to the gold table.\n",
    "# - Uses 'append' mode to add new records without overwriting.\n",
    "# - The table 'earthquake_events_gold' serves as the gold layer in the medallion architecture.\n",
    "df_with_location_sig_class.write.mode('append').saveAsTable('earthquake_events_gold')\n",
    "\n",
    "# ---------------------------\n",
    "# Additional Info:\n",
    "# - The gold layer adds business logic and enrichment (e.g., country code, significance class) to the cleansed data.\n",
    "# - This layer is optimized for analytics"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {
    "environmentId": "65375c3f-cd13-4809-8a5c-4b5f217249b7",
    "workspaceId": "2cfdb44b-710f-4814-b790-60e31d4f7df7"
   },
   "lakehouse": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default"
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
